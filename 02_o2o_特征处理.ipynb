{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_train = pd.read_csv('./data/ccf_offline_stage1_train.csv', keep_default_na=False, header=0)\n",
    "off_test = pd.read_csv('./data/ccf_offline_stage1_test_revised.csv',keep_default_na=False, header=0)\n",
    "on_train = pd.read_csv('./data/ccf_online_stage1_train.csv', keep_default_na=False, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更换特征名称\n",
    "off_train.columns=['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']\n",
    "off_test.columns = ['user_id','merchant_id','coupon_id','discount_rate','distance','date_received']\n",
    "on_train.columns = ['user_id','merchant_id','action','coupon_id','discount_rate','date_received','date']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据分批处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#将数据分为3个数据集 利用滑窗法\n",
    "#将2016年1月1日到4月13日的数据提取特征，利用4月14日的到5月14日的作为测试集\n",
    "#将2月1日到5月14日的作为数据集提取特征，利用5月15日6月15日的作为测试集\n",
    "#将3月15日到6月30日作为数据集提取特征，再测试7月1日到7月31日的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将2016年1月1日到4月13日的数据提取特征\n",
    "feature1 = off_train[(off_train.date >= '20160101') & (off_train.date <= '20160413') | (\n",
    "    (off_train.date == 'null') & (off_train.date_received >= '20160101') & (off_train.date_received <= '20160413'))]\n",
    "# 利用4月14日的到5月14日的作为测试集\n",
    "dataset1 = off_train[(off_train.date_received >= '201604014')\n",
    "                     & (off_train.date_received <= '20160514')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在2月1日到5月14日之间使用了券,只要领取时间在2月1日到5月14日之间,并包括没有数据中没有领取券的\n",
    "feature2 = off_train[(off_train.date >= '20160201') & (off_train.date <= '20160514') | (\n",
    "    (off_train.date == 'null') & (off_train.date_received >= '20160201') & (off_train.date_received <= '20160514'))]\n",
    "# 提取数据集2的测试集\n",
    "dataset2 = off_train[(off_train.date_received >= '20160515')\n",
    "                     & (off_train.date_received <= '20160615')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集3的特征为 取数据中领券和用券日期大于3月15日和小于6月30日的\n",
    "feature3 = off_train[((off_train.date >= '20160315') & (off_train.date <= '20160630')) | (\n",
    "    (off_train.date == 'null') & (off_train.date_received >= '20160315') & (off_train.date_received <= '20160630'))]\n",
    "# 使数据集3等于test集 没有label标签\n",
    "dataset3 = off_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_firstlastone(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    elif x > 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  # 表明这个优惠券只接受了一次\n",
    "\n",
    "def get_day_gap_before(s):\n",
    "    date_received, dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        # 将时间差转化为天数\n",
    "        this_gap = (dt.date(int(date_received[0:4]), int(date_received[4:6]), int(\n",
    "            date_received[6:8]))-dt.date(int(d[0:4]), int(d[4:6]), int(d[6:8]))).days\n",
    "        if this_gap > 0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps) == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "\n",
    "\n",
    "def get_day_gap_after(s):\n",
    "    date_received, dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (dt.datetime(int(d[0:4]), int(d[4:6]), int(d[6:8]))-dt.datetime(\n",
    "            int(date_received[0:4]), int(date_received[4:6]), int(date_received[6:8]))).days\n",
    "        if this_gap > 0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps) == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetOtherFeature(dataset):\n",
    "    # 对于测试集，提取用户的Id\n",
    "    dataset3 = dataset\n",
    "    t = dataset3[['user_id']]\n",
    "    # 相当于给原有数据加上一列，这个月用户收取的所有优惠券数目，并初始化为1\n",
    "    t['this_month_user_receive_all_coupon_count'] = 1\n",
    "\n",
    "    # 将t按照用户id进行分组，然后统计所有用户收取的优惠券数目,并初始化一个索引值\n",
    "    t = t.groupby('user_id').agg('sum').reset_index()\n",
    "    # 提取数据集的优惠券Id和用户Id\n",
    "    t1 = dataset3[['user_id', 'coupon_id']]\n",
    "    # 提取这个月用户收到的相同的优惠券的数量\n",
    "    t1['this_month_user_receive_same_coupn_count'] = 1\n",
    "    t1 = t1.groupby(['user_id', 'coupon_id']).agg('sum').reset_index()\n",
    "\n",
    "    # 提取数据集的用户id，优惠券id以及优惠券接收的时间\n",
    "    t2 = dataset3[['user_id', 'coupon_id', 'date_received']]\n",
    "\n",
    "    # 将数据转换为str类型\n",
    "    t2.date_received = t2.date_received.astype('str')\n",
    "    # 如果出现相同的用户接收相同的优惠券在接收时间上用‘：’连接上第n次接受优惠券的时间\n",
    "    t2 = t2.groupby(['user_id', 'coupon_id'])['date_received'].agg(\n",
    "        lambda x: ':'.join(x)).reset_index()\n",
    "    # 将接收时间的一组按着':'分开，这样就可以计算接受了优惠券的数量,apply是合并\n",
    "    t2['receive_number'] = t2.date_received.apply(lambda s: len(s.split(':')))\n",
    "    t2 = t2[t2.receive_number > 1]\n",
    "    # 最大接受的日期\n",
    "    t2['max_date_received'] = t2.date_received.apply(\n",
    "        lambda s: max([int(d) for d in s.split(':')]))\n",
    "    # 最小的接收日期\n",
    "    t2['min_date_received'] = t2.date_received.apply(\n",
    "        lambda s: min([int(d) for d in s.split(':')]))\n",
    "    t2 = t2[['user_id', 'coupon_id', 'max_date_received', 'min_date_received']]\n",
    "\n",
    "    t3 = dataset3[['user_id', 'coupon_id', 'date_received']]\n",
    "    # 将两表融合只保留左表数据,这样得到的表，相当于保留了最近接收时间和最远接受时间\n",
    "    t3 = pd.merge(t3, t2, on=['user_id', 'coupon_id'], how='left')\n",
    "    # 这个优惠券最近接受时间\n",
    "    t3['this_month_user_receive_same_coupon_lastone'] = t3.max_date_received - \\\n",
    "        t3.date_received.astype(int)\n",
    "    # 这个优惠券最远接受时间\n",
    "    t3['this_month_user_receive_same_coupon_firstone'] = t3.date_received.astype(\n",
    "        int)-t3.min_date_received\n",
    "\n",
    "    t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(\n",
    "        is_firstlastone)\n",
    "    t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(\n",
    "        is_firstlastone)\n",
    "    t3 = t3[['user_id', 'coupon_id', 'date_received', 'this_month_user_receive_same_coupon_lastone',\n",
    "             'this_month_user_receive_same_coupon_firstone']]\n",
    "    # 将表格中接收优惠券日期中为最近和最远的日期时置为1其余为0，若只接受了一次优惠券为-1\n",
    "\n",
    "    # 提取第四个特征,一个用户所接收到的所有优惠券的数量\n",
    "    t4 = dataset3[['user_id', 'date_received']]\n",
    "    t4['this_day_receive_all_coupon_count'] = 1\n",
    "    t4 = t4.groupby(['user_id', 'date_received']).agg('sum').reset_index()\n",
    "\n",
    "    # 提取第五个特征,一个用户不同时间所接收到不同优惠券的数量\n",
    "    t5 = dataset3[['user_id', 'coupon_id', 'date_received']]\n",
    "    t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "    t5 = t5.groupby(['user_id', 'coupon_id', 'date_received']\n",
    "                    ).agg('sum').reset_index()\n",
    "    # 一个用户不同优惠券 的接受时间\n",
    "    t6 = dataset3[['user_id', 'coupon_id', 'date_received']]\n",
    "    t6.date_received = t6.date_received.astype('str')\n",
    "    t6 = t6.groupby(['user_id', 'coupon_id'])['date_received'].agg(\n",
    "        lambda x: ':'.join(x)).reset_index()\n",
    "    # 重命名inplace代表深拷贝\n",
    "    t6.rename(columns={'date_received': 'dates'}, inplace=True)\n",
    "\n",
    "\n",
    "    t7 = dataset3[['user_id', 'coupon_id', 'date_received']]\n",
    "    # 将t6和t7融合\n",
    "    t7 = pd.merge(t7, t6, on=['user_id', 'coupon_id'], how='left')\n",
    "    # 注意这里所有的时间格式都已经是'str'格式\n",
    "    t7['date_received_date'] = t7.date_received.astype('str')+'-'+t7.dates\n",
    "    # print(t7)\n",
    "    t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "    t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "    t7 = t7[['user_id', 'coupon_id', 'date_received',\n",
    "             'day_gap_before', 'day_gap_after']]\n",
    "\n",
    "    # 将所有特征融合在一张表中\n",
    "    other_feature3 = pd.merge(t1, t, on='user_id')\n",
    "    other_feature3 = pd.merge(other_feature3, t3, on=['user_id', 'coupon_id'])\n",
    "    other_feature3 = pd.merge(other_feature3, t4, on=['user_id', 'date_received'])\n",
    "    other_feature3 = pd.merge(other_feature3, t5, on=[\n",
    "                              'user_id', 'coupon_id', 'date_received'])\n",
    "    other_feature3 = pd.merge(other_feature3, t7, on=[\n",
    "                              'user_id', 'coupon_id', 'date_received'])\n",
    "    return other_feature3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取优惠券的相关特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_discount_rate(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return float(s[0])\n",
    "    else:\n",
    "        return 1.0-float(s[1])/float(s[0])\n",
    "def get_discount_man(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[0])\n",
    "def get_discount_jian(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[1])\n",
    "\n",
    "def is_man_jian(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCouponFeature(dataset, feature):\n",
    "    # 对于数据集\n",
    "    # 将时间转化为第几周\n",
    "    # 显示时间是第几周\n",
    "    # tt是获取到的特征中消费的最大时间\n",
    "    dataset3 = dataset\n",
    "    tt = feature[feature.date != 'null'].date.unique().max()\n",
    "    dataset3['day_of_week'] = dataset3.date_received.astype('str').apply(\n",
    "        lambda x: date(int(x[0:4]), int(x[4:6]), int(x[6:8])).weekday()+1)\n",
    "    # 显示时间是几月\n",
    "    dataset3['day_of_month'] = dataset3.date_received.astype(\n",
    "        'str').apply(lambda x: int(x[6:8]))\n",
    "    # 显示时期和截止日之间的天数\n",
    "    dataset3['days_distance'] = dataset3.date_received.astype('str').apply(\n",
    "        lambda x: (date(int(x[0:4]), int(x[4:6]), int(x[6:8]))-date(int(tt[0:4]), int(tt[4:6]), int(tt[6:8]))).days)\n",
    "    # 显示满了多少钱后开始减\n",
    "    dataset3['discount_man'] = dataset3.discount_rate.apply(get_discount_man)\n",
    "    # 显示满减的减少的钱\n",
    "    dataset3['discount_jian'] = dataset3.discount_rate.apply(get_discount_jian)\n",
    "    # 返回优惠券是否是满减券\n",
    "    dataset3['is_man_jian'] = dataset3.discount_rate.apply(is_man_jian)\n",
    "    # 显示打折力度\n",
    "    dataset3['discount_rate'] = dataset3.discount_rate.apply(\n",
    "        calc_discount_rate)\n",
    "    d = dataset3[['coupon_id']]\n",
    "    d['coupon_count'] = 1\n",
    "    # 显示每一种优惠券的数量\n",
    "    d = d.groupby('coupon_id').agg('sum').reset_index()\n",
    "\n",
    "    dataset3 = pd.merge(dataset3, d, on='coupon_id', how='left')\n",
    "    return dataset3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取商品的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMerchantFeature(feature):\n",
    "    #提取商品的特征\n",
    "    #对于数据集\n",
    "    feature3 = feature\n",
    "    merchant3 = feature3[['merchant_id','coupon_id','distance','date_received','date']]\n",
    "\n",
    "    t = merchant3[['merchant_id']]\n",
    "    #删除重复行数据\n",
    "    t.drop_duplicates(inplace=True)\n",
    "\n",
    "    #显示卖出的商品\n",
    "    t1 = merchant3[merchant3.date!='null'][['merchant_id']]\n",
    "    t1['total_sales'] = 1\n",
    "    #显示每个商品的销售数量\n",
    "    t1 = t1.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "\n",
    "    #显示使用了优惠券消费的商品，正样本\n",
    "    t2 = merchant3[(merchant3.date!='null')&(merchant3.coupon_id!='null')][['merchant_id']]\n",
    "    t2['sales_use_coupon'] = 1\n",
    "    t2 = t2.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "\n",
    "    #显示了商品的优惠券的总数量\n",
    "    t3 = merchant3[merchant3.coupon_id != 'null'][['merchant_id']]\n",
    "    t3 ['total_coupon'] = 1\n",
    "    t3 = t3.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "    #显示商品销量和距离的关系\n",
    "    t4 = merchant3[(merchant3.date != 'null')&(merchant3.coupon_id != 'null')][['merchant_id','distance']]\n",
    "    #把数据中的null值全部替换为-1\n",
    "    t4.replace('null',-1,inplace=True)\n",
    "    t4.distance = t4.distance.astype('int')\n",
    "    #再把数据中的-1全部替换为NaN\n",
    "    t4.replace(-1,np.nan,inplace=True)\n",
    "\n",
    "    #返回用户离商品的距离最小值\n",
    "    t5 = t4.groupby('merchant_id').agg('min').reset_index()\n",
    "    t5.rename(columns={'distance':'merchant_min_distance'},inplace = True)\n",
    "\n",
    "    #返回用户离商品的距离最大值\n",
    "    t6 = t4.groupby('merchant_id').agg('max').reset_index()\n",
    "    t6.rename(columns={'distance':'merchant_max_distance'},inplace = True)\n",
    "    #print(t6)\n",
    "\n",
    "    #返回距离的平均值\n",
    "    t7 = t4.groupby('merchant_id').agg('mean').reset_index()\n",
    "    t7.rename(columns = {'distance':'merchant_mean_distance'},inplace= True)\n",
    "\n",
    "    #返回距离的中位值\n",
    "    t8 = t4.groupby('merchant_id').agg('median').reset_index()\n",
    "    t8.rename(columns={'distance':'merchant_median_distance'},inplace = True)\n",
    "\n",
    "    merchant3_feature = pd.merge(t,t1,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,t2,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,t3,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,t5,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,t6,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,t7,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,t8,on='merchant_id',how='left')\n",
    "\n",
    "    #将数据中的NaN用0来替换\n",
    "    merchant3_feature.sales_use_coupon = merchant3_feature.sales_use_coupon.replace(np.nan,0)\n",
    "    #即优惠券的使用率\n",
    "    merchant3_feature['merchant_coupon_transfer_rate'] = merchant3_feature.sales_use_coupon.astype('float')/merchant3_feature.total_coupon\n",
    "    #即卖出商品中使用优惠券的占比\n",
    "    merchant3_feature['coupon_rate'] = merchant3_feature.sales_use_coupon.astype('float') / merchant3_feature.total_sales\n",
    "    #将数据中的NaN用0来替换\n",
    "    merchant3_feature.total_coupon = merchant3_feature.total_coupon.replace(np.nan,0)\n",
    "    return merchant3_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户的相关信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_date_datereceived_gap(s):\n",
    "    s = s.split(':')\n",
    "    return (date(int(s[0][0:4]), int(s[0][4:6]), int(s[0][6:8])) - date(int(s[1][0:4]), int(s[1][4:6]), int(s[1][6:8]))).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetUserRelateInfo(feature):\n",
    "    \n",
    "    feature3 = feature\n",
    "    user3 = feature3[['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']]\n",
    "\n",
    "    t = user3[['user_id']]\n",
    "    #去掉数据中重复的用户Id\n",
    "    t.drop_duplicates(inplace=True)\n",
    "\n",
    "    #用户购买商品的种类数\n",
    "    t1 = user3[user3.date!='null'][['user_id','merchant_id']]\n",
    "    #同样去掉重复用的用户id和商品id\n",
    "    t1.drop_duplicates(inplace=True)\n",
    "    t1.merchant_id = 1\n",
    "    t1 = t1.groupby('user_id').agg('sum').reset_index()\n",
    "    t1.rename(columns={'merchant_id':'count_merchant'},inplace=True)\n",
    "\n",
    "\n",
    "    #使用了优惠券购买商品的用户id和距离\n",
    "    t2 = user3[(user3.date!='null')&(user3.coupon_id!='null')][['user_id','distance']]\n",
    "    #将null值替换为-1\n",
    "    t2.replace('null',-1,inplace=True)\n",
    "    t2.distance = t2.distance.astype('int')#转换数据类型为int\n",
    "    t2.replace(-1,np.nan,inplace=True)\n",
    "\n",
    "    #得到使用优惠券购买商品的用户离店铺的最短距离\n",
    "    t3 = t2.groupby('user_id').agg('min').reset_index()\n",
    "    t3.rename(columns={'distance':'user_min_distance'},inplace=True)\n",
    "\n",
    "    #得到最大距离\n",
    "    t4 = t2.groupby('user_id').agg('max').reset_index()\n",
    "    t4.rename(columns={'distance':'user_max_distance'},inplace=True)\n",
    "\n",
    "    #得到平均距离\n",
    "    t5 = t2.groupby('user_id').agg('mean').reset_index()\n",
    "    t5.rename(columns={'distance':'user_mean_distance'},inplace=True)\n",
    "\n",
    "    #得到中间距离\n",
    "    t6 = t2.groupby('user_id').agg('median').reset_index()\n",
    "    t6.rename(columns={'distance':'user_median_distance'},inplace=True)\n",
    "\n",
    "    #每个用户使用优惠券购买的物品数量\n",
    "    t7 = user3[(user3.date != 'null')&(user3.coupon_id != 'null')][['user_id']]\n",
    "    t7['buy_use_coupon'] = 1\n",
    "    t7 = t7.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "    #购买物品的总数\n",
    "    t8 = user3[user3.date != 'null'][['user_id']]\n",
    "    t8['buy_total'] = 1\n",
    "    t8 = t8.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "    #接受的优惠券的总数\n",
    "    t9 = user3[user3.coupon_id != 'null'][['user_id']]\n",
    "    t9['coupon_received'] = 1\n",
    "    t9 = t9.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "    #接受到优惠券的日期和使用之间的间隔\n",
    "    t10 = user3[(user3.date_received != 'null')&(user3.date != 'null')][['user_id','date_received','date']]\n",
    "    t10['user_date_datereceived_gap'] = t10.date + ':'+ t10.date_received\n",
    "    t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.apply(get_user_date_datereceived_gap)\n",
    "    t10 = t10[['user_id','user_date_datereceived_gap']]\n",
    "\n",
    "    #将用户优惠券使用时间的间隔取平均数\n",
    "    t11 = t10.groupby('user_id').agg('mean').reset_index()\n",
    "    t11.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "    #间隔天数的最小值\n",
    "    t12 = t10.groupby('user_id').agg('min').reset_index()\n",
    "    t12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "    #间隔天数的最大值\n",
    "    t13 = t10.groupby('user_id').agg('max').reset_index()\n",
    "    t13.rename(columns={'user_date_datareceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "    #将提取的特征合并\n",
    "    user3_feature = pd.merge(t,t1,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t3,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t4,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t5,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t6,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t7,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t8,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t9,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t11,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t12,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t13,on='user_id',how='left')\n",
    "\n",
    "    user3_feature.count_merchant = user3_feature.count_merchant.replace(np.nan,0)\n",
    "    user3_feature.buy_user_coupon = user3_feature.buy_use_coupon.replace(np.nan,0)\n",
    "    user3_feature['buy_use_coupon_rate'] = user3_feature.buy_use_coupon.astype('float') / user3_feature.buy_total.astype('float')#使用优惠券购买的商品占总数的多少\n",
    "    user3_feature['user_coupon_transfer_rate'] = user3_feature.buy_use_coupon.astype('float') / user3_feature.coupon_received.astype('float')\n",
    "    user3_feature.buy_total = user3_feature.buy_total.replace(np.nan,0)#将数据中的NaN值转为0\n",
    "    user3_feature.coupon_received = user3_feature.coupon_received.replace(np.nan,0)\n",
    "    return user3_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户和商家之间的特征关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetUserMerchantRelateInfo(feature):\n",
    "    #4.user_merchant:\n",
    "    #times_user_buy_merchant_before. \n",
    "    feature3 = feature\n",
    "    all_user_merchant = feature3[['user_id','merchant_id']]\n",
    "    all_user_merchant.drop_duplicates(inplace=True)\n",
    "    \n",
    "    #只保留销售了商品的商户id\n",
    "    t = feature3[['user_id','merchant_id','date']]\n",
    "    t = t[t.date!='null'][['user_id','merchant_id']]\n",
    "    \n",
    "    #用户一共买了这家商户的多少商品\n",
    "    t['user_merchant_buy_total'] = 1\n",
    "    t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t.drop_duplicates(inplace=True)\n",
    "\n",
    "    t1 = feature3[['user_id','merchant_id','coupon_id']]\n",
    "    t1 = t1[t1.coupon_id!='null'][['user_id','merchant_id']]\n",
    "    \n",
    "    #用户一共收到一个商户的多少优惠券\n",
    "    t1['user_merchant_received'] = 1\n",
    "    t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t1.drop_duplicates(inplace = True)\n",
    "\n",
    "    t2 = feature3[['user_id','merchant_id','date','date_received']]\n",
    "    t2 = t2[(t2.date!='null')&(t2.date_received!='null')][['user_id','merchant_id']]\n",
    "    \n",
    "    #用户在一家商户中使用优惠券购买的商品的数目\n",
    "    t2['user_merchant_buy_use_coupon'] = 1\n",
    "    t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t2.drop_duplicates(inplace = True)\n",
    "\n",
    "    #用户在一家商家的所有记录总数\n",
    "    t3 = feature3[['user_id','merchant_id']]\n",
    "    t3['user_merchant_any'] = 1\n",
    "    t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t3.drop_duplicates(inplace = True)\n",
    "\n",
    "    t4 = feature3[['user_id','merchant_id','date','coupon_id']]\n",
    "    t4 = t4[(t4.date!='null')&(t4.coupon_id=='null')][['user_id','merchant_id']]\n",
    "    \n",
    "    #用户没有使用优惠券购买的商品的数目\n",
    "    t4['user_merchant_buy_common'] = 1\n",
    "    t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t4.drop_duplicates(inplace = True)\n",
    "\n",
    "    user_merchant3 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant3 = pd.merge(user_merchant3,t1,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant3 = pd.merge(user_merchant3,t2,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant3 = pd.merge(user_merchant3,t3,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant3 = pd.merge(user_merchant3,t4,on=['user_id','merchant_id'],how='left')\n",
    "    \n",
    "    #都是针对一家商户和一个用户\n",
    "    user_merchant3.user_merchant_buy_use_coupon = user_merchant3.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "    user_merchant3.user_merchant_buy_common = user_merchant3.user_merchant_buy_common.replace(np.nan,0)\n",
    "    #y优惠券的转换率，用户使用了的优惠券/一共收到的优惠券\n",
    "    user_merchant3['user_merchant_coupon_transfer_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_received.astype('float')\n",
    "    #用户使用优惠券的概率，在一家商户使用优惠券购买的商品/在一家商户购买商品的总数\n",
    "    user_merchant3['user_merchant_coupon_buy_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "    #用户在商户消费的概率 用户在商户购买的总数/在一家商户浏览的总次数\n",
    "    user_merchant3['user_merchant_rate'] = user_merchant3.user_merchant_buy_total.astype('float') / user_merchant3.user_merchant_any.astype('float')\n",
    "    #用户在一家商户不适用优惠券购买的概率 普通购买的商品数/购买商品的总数\n",
    "    user_merchant3['user_merchant_common_buy_rate'] = user_merchant3.user_merchant_buy_common.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "    return user_merchant3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(s):\n",
    "    s = s.split(':')\n",
    "    if s[0]=='null':\n",
    "        return 0\n",
    "    elif (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8]))-date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days<=15:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateData(dataset, feature, label=True):\n",
    "    # 获取各个特征处理后的结果\n",
    "    coupon_feature = GetCouponFeature(dataset, feature)\n",
    "    merchant_feature = GetMerchantFeature(feature)\n",
    "    user_feature = GetUserRelateInfo(feature)\n",
    "    user_merchant = GetUserMerchantRelateInfo(feature)\n",
    "    other_feature = GetOtherFeature(dataset)\n",
    "\n",
    "    dataset = pd.merge(coupon_feature, merchant_feature,\n",
    "                       on='merchant_id', how='left')\n",
    "    dataset = pd.merge(dataset, user_feature, on='user_id', how='left')\n",
    "    dataset = pd.merge(dataset, user_merchant, on=[\n",
    "                       'user_id', 'merchant_id'], how='left')\n",
    "    dataset = pd.merge(dataset, other_feature, on=[\n",
    "                       'user_id', 'coupon_id', 'date_received'], how='left')\n",
    "    dataset.drop_duplicates(inplace=True)\n",
    "\n",
    "    dataset.user_merchant_buy_total = dataset.user_merchant_buy_total.replace(\n",
    "        np.nan, 0)\n",
    "    dataset.user_merchant_any = dataset.user_merchant_any.replace(np.nan, 0)\n",
    "    dataset.user_merchant_received = dataset.user_merchant_received.replace(\n",
    "        np.nan, 0)\n",
    "    dataset['is_weekend'] = dataset.day_of_week.apply(\n",
    "        lambda x: 1 if x in (6, 7) else 0)\n",
    "    weekday_dummies = pd.get_dummies(dataset.day_of_week)\n",
    "    weekday_dummies.columns = [\n",
    "        'weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "    dataset = pd.concat([dataset, weekday_dummies], axis=1)\n",
    "\n",
    "    # 如果是训练集要记得处理label标签值  但是在测试集中不用处理label标签 注意off_train和off_test字段\n",
    "    if label:\n",
    "        dataset['label'] = dataset.date.astype(\n",
    "            'str') + ':' + dataset.date_received.astype('str')\n",
    "        dataset.label = dataset.label.apply(get_label)\n",
    "        dataset.drop(['merchant_id', 'day_of_week', 'date', 'date_received',\n",
    "                     'coupon_count'], axis=1, inplace=True)\n",
    "\n",
    "    else:\n",
    "        dataset.drop(['merchant_id', 'day_of_week', 'coupon_count'],\n",
    "                 axis=1, inplace=True)\n",
    "        \n",
    "    # 所有的表都要一起处理null\n",
    "    dataset = dataset.replace('null', np.nan)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:89: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/houxiaojun/.virtualenvs/testai/lib/python3.7/site-packages/ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "GenerateData1 = GenerateData(dataset1, feature1)\n",
    "GenerateData2 = GenerateData(dataset2, feature2)\n",
    "GenerateData3 = GenerateData(dataset3, feature3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存处理好的特征值, 以便后续使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenerateData1.to_csv('./GenerateData1.csv', index=None)\n",
    "GenerateData2.to_csv('./GenerateData2.csv', index=None)\n",
    "GenerateData3.to_csv('./GenerateData3.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
